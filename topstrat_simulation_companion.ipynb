{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4764ed2a-dc62-4141-96e1-332477e87434",
   "metadata": {},
   "source": [
    "# UMAP-HDBSCAN on simulated populations\n",
    "\n",
    "This notebook is a companion to the simulation data provided at `10.5281/zenodo.17545804`. The simulations were used as experiments described in [Diaz-Papkovich et al (2025)](https://www.biorxiv.org/content/10.1101/2023.07.06.548007v2).\n",
    "\n",
    "For code used to generate UMAP embeddings, see the Topstrat repo: https://github.com/diazale/topstrat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34b4649-8cac-4fe9-91f5-09e45b7e2a51",
   "metadata": {},
   "source": [
    "## Convert vcf to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f36d6702-71f9-4ccd-b0bd-b2cdf43959c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import allel\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02c0cc83-659e-4da7-b546-16fa478a493f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"popsim_data\"\n",
    "data_dir = os.path.join(base_dir, \"sims\")\n",
    "out_dir = os.path.join(base_dir, \"numpy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b174f7-3506-46ed-b1d3-880b7d2069df",
   "metadata": {},
   "source": [
    "## Libraries and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "274cd61b-9c9a-4f72-90e6-8852698eadf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "import hdbscan\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import time\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.metrics import v_measure_score\n",
    "from sklearn.metrics import fowlkes_mallows_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e2acdbe-db45-40e4-80fe-6247bf1e6be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract UMAP parameters from a file name\n",
    "# e.g. \"UMAP_NC5_NN50_MD0_2025-10-09_american_admix_\"\n",
    "def extract_umap_params(instr_):\n",
    "    # Intake: A UMAP filename formatted that I can extract the UMAP parameters\n",
    "    # Output: number components, number neighbours, minimum distance\n",
    "    nc_ = instr_.split(\"_NC\")[1].split(\"_\")[0]\n",
    "    nn_ = instr_.split(\"_NN\")[1].split(\"_\")[0]\n",
    "    md_ = instr_.split(\"_MD\")[1].split(\"_\")[0]\n",
    "\n",
    "    return nc_, nn_, md_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2c6aeee-2e04-45a4-b5ce-11c9eb1a728c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot data\n",
    "# Plots the first two dimensions of coords_ regardless of the matrix\n",
    "def plotter(coords_, labels_, title_, size_=1, tick_params_=False):\n",
    "    for label_ in set(labels_) - {-1}:\n",
    "        plt.scatter(\n",
    "            coords_[label_==labels_,0],\n",
    "            coords_[label_==labels_,1],\n",
    "            s=size_\n",
    "        )\n",
    "    plt.scatter(\n",
    "        coords_[labels_==-1,0],\n",
    "        coords_[labels_==-1,1],\n",
    "        s=size_,\n",
    "        c=\"black\"\n",
    "    )\n",
    "\n",
    "    if tick_params_:\n",
    "        plt.tick_params(bottom=True, left=True, labelbottom=True, labelleft=True)\n",
    "    else:\n",
    "        plt.tick_params(bottom=False, left=False, labelbottom=False, labelleft=False)\n",
    "            \n",
    "    plt.title(title_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a10e87f-c586-49ea-91c1-a0949a27374e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at how parameters affect which points get assigned to clusters\n",
    "def four_split(in_proj, eps_list=[0.5], mps_list=[50, 25, 15, 10], labels=False, model_label=\"Unspecified\"):\n",
    "\n",
    "    fig, axs = plt.subplots(2,2, figsize=(10,10))\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    \n",
    "    #eps = [0.5]\n",
    "    #mps = [50, 25, 15, 10]\n",
    "    \n",
    "    dim1 = 0\n",
    "    dim2 = 1\n",
    "    \n",
    "    # Add HDBSCAN data\n",
    "    clusterers = list()\n",
    "    cluster_label_list = list()\n",
    "    num_clusters = list()\n",
    "    num_unclustered = list()\n",
    "    \n",
    "    for m in mps_list:\n",
    "        for e in eps_list:\n",
    "            clusterer = hdbscan.HDBSCAN(min_cluster_size=m, cluster_selection_epsilon=e).fit(in_proj)\n",
    "            clusterers.append(clusterer)\n",
    "            cluster_labels = clusterer.labels_\n",
    "            cluster_label_list.append(cluster_labels)\n",
    "            \n",
    "            num_clusters.append(len(set(cluster_labels[cluster_labels!=-1])))\n",
    "            num_unclustered.append(np.sum(cluster_labels==-1))\n",
    "\n",
    "            # Arrange the four grids\n",
    "            # Three possibilities: 4 epsilon values, 1 mp; 2 of each; 1 epsilon, 4 mp\n",
    "            # overly fancy way to determine grid position from index in a 1D array.\n",
    "            if len(mps_list)==4:\n",
    "                # One epsilon value, four MP values\n",
    "                xa = int(np.where(np.array(mps_list)==m)[0][0]/2)\n",
    "                ya = np.where(np.array(mps_list)==m)[0][0] % 2\n",
    "            elif len(eps_list)==4:\n",
    "                # Four epsilon values, one MP value\n",
    "                xa = int(np.where(np.array(eps_list)==e)[0][0]/2)\n",
    "                ya = np.where(np.array(eps_list)==e)[0][0] % 2\n",
    "            elif len(mps_list)==2 and len(eps_list)==2:\n",
    "                xa = np.where(np.array(mps_list)==m)[0][0] % 2\n",
    "                ya = np.where(np.array(eps_list)==e)[0][0] % 2\n",
    "            #    print()\n",
    "\n",
    "            if not labels:\n",
    "                # Plot all points. Those assigned to a cluster are black, those not are red.\n",
    "                axs[xa, ya].scatter(\n",
    "                    in_proj[:,dim1],\n",
    "                    in_proj[:,dim2],\n",
    "                    s = 3\n",
    "                )\n",
    "                axs[xa, ya].scatter(\n",
    "                    in_proj[cluster_labels==-1,dim1],\n",
    "                    in_proj[cluster_labels==-1,dim2],\n",
    "                    s = 3,\n",
    "                    c=\"red\"\n",
    "                )\n",
    "                axs[xa, ya].set_title(\"(MP, EPS)=(\" + str(m) + \", \" + str(e) + \")\" + \"\\n\" + \\\n",
    "                                     \"unclustered=\" + str(num_unclustered[-1]) + \", \" + \\\n",
    "                                     \"num_clusters=\" + str(num_clusters[-1]))\n",
    "            else:\n",
    "                # Plot the labels specified by HDBSCAN\n",
    "                for cl in (set(cluster_labels)):\n",
    "                    if cl!=-1:\n",
    "                        axs[xa, ya].scatter(\n",
    "                        in_proj[cluster_labels==cl,dim1],\n",
    "                        in_proj[cluster_labels==cl,dim2],\n",
    "                        s = 3\n",
    "                )\n",
    "                axs[xa, ya].scatter(\n",
    "                    in_proj[cluster_labels==-1,dim1],\n",
    "                    in_proj[cluster_labels==-1,dim2],\n",
    "                    s = 5,\n",
    "                    c=\"black\",\n",
    "                    marker=\"o\"\n",
    "                )\n",
    "                axs[xa, ya].set_title(\"(MP, EPS)=(\" + str(m) + \", \" + str(e) + \")\" + \"\\n\" + \\\n",
    "                             \"unclustered=\" + str(num_unclustered[-1]) + \", \" + \\\n",
    "                             \"num_clusters=\" + str(num_clusters[-1]))\n",
    "                axs[xa, ya].set_xticks([])\n",
    "                axs[xa, ya].set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3aec273-a93f-4b26-8bd1-396e6576c5ee",
   "metadata": {},
   "source": [
    "# Example clustering and analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2105737d-f592-4bc1-adf5-428dc38b76a9",
   "metadata": {},
   "source": [
    "## Set up directories and known population labels\n",
    "\n",
    "This assumes you have already run UMAP on each of the simulated replicates. From here, it will import UMAP and run HDBSCAN. It also supports PCA and k-means if you want to compare. Otherwise, comment those portions of code out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f77286a-84df-45a3-9cd9-93c4180fb385",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"popsims\"\n",
    "\n",
    "# The three experiments are stored in:\n",
    "# american_admix\n",
    "# stepping_stone\n",
    "# neutral_ooa_simulations\n",
    "\n",
    "data_dir = {}\n",
    "\n",
    "data_dir[\"ooa_neutral\"] = os.path.join(base_dir, \"neutral_ooa_simulations\")\n",
    "data_dir[\"stepping_stone\"] = os.path.join(base_dir, \"stepping_stone\")\n",
    "data_dir[\"admix\"] = os.path.join(base_dir, \"american_admix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a36effa-7c66-4231-a34c-5276ad816594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up some arrays of ground truth populations as defaultdicts of lists\n",
    "ground_truths = defaultdict(list)\n",
    "\n",
    "ground_truths[\"ooa_neutral\"] = np.array(\n",
    "    [0]*1000 + [1]*1000 + [2]*1000\n",
    ")\n",
    "ground_truths[\"stepping_stone\"] = np.array(\n",
    "    [0]*500 + [1]*500 + [2]*500 + [3]*500 + [4]*500 + [5]*500 + [6]*500 + [7]*500 + [8]*500\n",
    ")\n",
    "ground_truths[\"admix\"] = np.array(\n",
    "    [0]*1000 + [1]*1000 + [2]*1000 + [3]*1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d653ce15-2645-4cb0-b22c-c6514d57ac1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_path = os.path.join(data_dir[\"ooa_neutral\"], \"embeddings\", \"umap\")\n",
    "pca_path = os.path.join(data_dir[\"ooa_neutral\"], \"embeddings\", \"pca\")\n",
    "\n",
    "ground_truth = ground_truths[\"ooa_neutral\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a5620a-eb1e-47c7-94a2-44404bd7fdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This loops through the PCA and UMAP embeddings of the 100 simulated populations.\n",
    "umap_embeddings = dict()\n",
    "pca_embeddings = dict()\n",
    "\n",
    "# HDBSCAN parameters (or UMAP parameters if necessary)\n",
    "es = [0.5]\n",
    "mps = [25,50]\n",
    "\n",
    "hdbscan_clusters = dict()\n",
    "kmeans_clusters = dict()\n",
    "\n",
    "# For HDBSCAN\n",
    "num_clusters = dict()\n",
    "num_unclustered = dict()\n",
    "\n",
    "# Cluster diagnostics versus ground truth labels\n",
    "kmeans_ari = []\n",
    "kmeans_vm = []\n",
    "kmeans_fw = []\n",
    "\n",
    "hdbscan_ari = defaultdict(list)\n",
    "hdbscan_vm = defaultdict(list)\n",
    "hdbscan_fw = defaultdict(list)\n",
    "\n",
    "# Set up a variable to flag the highest cluster metric for each replicate.\n",
    "# This works across grid searches if you're interested in which parameter sets do well.\n",
    "max_ari = defaultdict(int)\n",
    "max_vm = defaultdict(int)\n",
    "max_fw = defaultdict(int)\n",
    "\n",
    "correct_count = defaultdict(bool)\n",
    "\n",
    "# Assumes your files are stored as [base_file]_[rep].npz with data stored in array [\"arr_0\"]\n",
    "base_file = \"UMAP_NC2_NN50_MD0.0001_2025-09-30_neutral_simulation_\" \n",
    "\n",
    "for rep in range(1,101):\n",
    "    print(\"Replicate:\", rep)\n",
    "    umap_embeddings[rep] = np.load(os.path.join(umap_path, base_file + str(rep) + \".npz\"))[\"arr_0\"]\n",
    "    pca_embeddings[rep] = np.load(os.path.join(pca_path, \"neutral_simulation_\" + str(rep) + \"_PCA.npz\"))[\"arr_0\"][:,:10]\n",
    "\n",
    "    # K-means, for comparison\n",
    "    kmeans = sklearn.cluster.KMeans(n_clusters=len(set(ground_truth))).fit(pca_embeddings[rep][:,:len(set(ground_truth))])\n",
    "    kmeans_clusters[rep] = kmeans.labels_\n",
    "\n",
    "    kmeans_ari.append(adjusted_rand_score(ground_truth, kmeans_clusters[rep]))\n",
    "    kmeans_vm.append(v_measure_score(ground_truth, kmeans_clusters[rep]))\n",
    "    kmeans_fw.append(fowlkes_mallows_score(ground_truth, kmeans_clusters[rep]))\n",
    "    \n",
    "    for e in es:\n",
    "        for m in mps:\n",
    "            # Generate HDBSCAN clusters\n",
    "            clusterer = hdbscan.HDBSCAN(min_cluster_size=m, cluster_selection_epsilon=e).fit(umap_embeddings[rep])\n",
    "            hdbscan_clusters[(rep, e, m)] = clusterer.labels_\n",
    "            num_clusters[(rep, e, m)] = len(set(hdbscan_clusters[(rep, e, m)][hdbscan_clusters[(rep, e, m)]!=-1]))\n",
    "            num_unclustered[(rep, e, m)] = np.sum(hdbscan_clusters[(rep, e, m)]==-1)\n",
    "\n",
    "            # Various clustering metrics\n",
    "            hdbscan_ari[(rep, e, m)].append(adjusted_rand_score(ground_truth, hdbscan_clusters[(rep, e, m)]))\n",
    "            hdbscan_vm[(rep, e, m)].append(v_measure_score(ground_truth, hdbscan_clusters[(rep, e, m)]))\n",
    "            hdbscan_fw[(rep, e, m)].append(fowlkes_mallows_score(ground_truth, hdbscan_clusters[(rep, e, m)]))\n",
    "\n",
    "            # Check if this is the highest clustering metric for the replicate\n",
    "            # Useful in a grid search to see if any parameters do particularly well\n",
    "            max_ari[rep] = max(max_ari[rep], adjusted_rand_score(ground_truth, hdbscan_clusters[(rep, e, m)]))\n",
    "            max_vm[rep] = max(max_vm[rep], v_measure_score(ground_truth, hdbscan_clusters[(rep, e, m)]))\n",
    "            max_fw[rep] = max(max_fw[rep], fowlkes_mallows_score(ground_truth, hdbscan_clusters[(rep, e, m)]))\n",
    "\n",
    "            # Check if any set of parameters in this replicate gets the number of clusters right\n",
    "            if num_clusters[(rep, e, m)]==len(set(ground_truth)):\n",
    "                correct_count[rep] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ec4b61-b62f-4c53-a3a4-49916b0e443c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the highest and lowest HDBSCAN ARI w.r.t. population labels\n",
    "min_ari = 1\n",
    "max_ari = 0\n",
    "\n",
    "for k in hdbscan_ari.keys():\n",
    "    ari_val = hdbscan_ari[k][0]\n",
    "    if ari_val > max_ari:\n",
    "        max_key = k\n",
    "        max_ari = ari_val\n",
    "    if ari_val < min_ari:\n",
    "        min_key = k\n",
    "        min_ari = ari_val\n",
    "\n",
    "max_rep = max_key[0]\n",
    "min_rep = min_key[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0f33b7-ad8d-44d0-b64d-59c1fb8ebed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the highest ARI \n",
    "plotter(umap_embeddings[max_rep], ground_truth, \"Highest-ARI UMAP-HDBSCAN (colours are ground truth)\", size_=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8137bd0d-ac7b-4701-8235-788af926345b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter(umap_embeddings[max_rep], temp, \"Highest-ARI UMAP-HDBSCAN (colours are clusters)\", size_=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c05222b-6217-4399-9fba-62d0fcc356a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the lowest ARI\n",
    "plotter(umap_embeddings[min_rep], ground_truth, \"Lowest-ARI UMAP-HDBSCAN (colours are ground truth)\", size_=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d9a1fa-1fbf-4f76-9245-44d1db5a3de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter(umap_embeddings[min_rep], hdbscan_clusters[min_key], \"Lowest-ARI UMAP-HDBSCAN (colours are clusters)\", size_=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1dcf4e-4f75-497b-93c0-74d2a439359b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the embedding with the lowest HDBSCAN ARI.\n",
    "# Try a grid search of HDBSCAN parameters to see what (if anything) changes.\n",
    "k = min_key\n",
    "four_split(umap_embeddings[k[0]], mps_list=[25], eps_list=[0.5, 0.3, 0.2, 0.1], labels=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
